{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweets\n",
    "\n",
    "Pierre Mulliez individual assignment \n",
    "\n",
    "Lets inspect the dataset:\n",
    "\n",
    "## Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About this analysis** \n",
    "<br>\n",
    "We would like to know if a tweet represents a disaster or not.\n",
    "<br>\n",
    "<br>\n",
    "**Why this analysis**\n",
    "<br>\n",
    "Prevention can save lives, with a population connected to social media like never before tweets analysis can optimize the responce time of rescue services.\n",
    "<br>\n",
    "<br>\n",
    "**How** \n",
    "<ul>\n",
    "<li> Exploding the text of the original datasets</li>\n",
    "<li> Cleaning and Standardizing the dataset along the way</li>\n",
    "    <ul>\n",
    "        <li> Duplicates values</li>\n",
    "        <li> Entry errors</li>\n",
    "    </ul>\n",
    "<li> Creating and joigning other datasets </li>\n",
    "    <ul>\n",
    "        <li> Sentiment analysis from the data architecture class</li>\n",
    "        <li> Built my own disaster dataset reference words</li>\n",
    "    </ul>\n",
    "<li> note: I decided not to use the target variable int he exploratory analysis as this would be cheating </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Insights** \n",
    "<br>\n",
    "**Answering key business questions**\n",
    "\n",
    "1. Do the persons need assistance ?\n",
    "2. Gravity of the situation ?\n",
    "3. Can we infer a state with a higher rate of incidents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/nlp-getting-started/data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing APIs\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining dataset's schema \n",
    "disasterSchema = StructType(\\\n",
    "    [StructField(\"id\",IntegerType(),True),\\\n",
    "     StructField(\"keyword\",StringType(),True),\\\n",
    "     StructField(\"text\",StringType(),True),\\\n",
    "     StructField(\"target\",IntegerType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------------------+------+\n",
      "| id|keyword|location|                text|target|\n",
      "+---+-------+--------+--------------------+------+\n",
      "|  1|   null|    null|Our Deeds are the...|     1|\n",
      "|  4|   null|    null|Forest fire near ...|     1|\n",
      "|  5|   null|    null|All residents ask...|     1|\n",
      "+---+-------+--------+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n",
      "+------------+\n",
      "|Total_tweets|\n",
      "+------------+\n",
      "|        8387|\n",
      "+------------+\n",
      "\n",
      "+--------------------+\n",
      "|Total__sample_tweets|\n",
      "+--------------------+\n",
      "|                5052|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disaster_with_schema = spark.read.load(\"data.csv\",\n",
    "                     format=\"csv\", sep=\",\", Schema=disasterSchema, header=\"true\", mode = \"PERMISSIVE\")\n",
    "print(disaster_with_schema.show(3))\n",
    "disaster_with_schema.select(count(\"id\").alias(\"Total_tweets\")).show()\n",
    "\n",
    "#sampling the dataset\n",
    "sample_disaster = disaster_with_schema.sample(fraction = 0.6, seed=1234)\n",
    "sample_disaster.select(count(\"id\").alias(\"Total__sample_tweets\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id keyword location                                               text  \\\n",
       "0  1    None     None  Our Deeds are the Reason of this #earthquake M...   \n",
       "1  4    None     None             Forest fire near La Ronge Sask. Canada   \n",
       "2  5    None     None  All residents asked to 'shelter in place' are ...   \n",
       "3  6    None     None  13,000 people receive #wildfires evacuation or...   \n",
       "4  7    None     None  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_with_schemapd = disaster_with_schema.toPandas()\n",
    "disaster_with_schemapd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentimentschema\n",
    "sentimentSchema = StructType(\\\n",
    "    [StructField(\"intensivity\",StringType(),True),\\\n",
    "     StructField(\"numb\",IntegerType(),True),\\\n",
    "     StructField(\"word\",StringType(),True),\\\n",
    "     StructField(\"type\",StringType(),True),\\\n",
    "     StructField(\"ny\",StringType(),True),\\\n",
    "     StructField(\"positivity\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+----+---+--------+\n",
      "|     _c0|_c1|        _c2| _c3|_c4|     _c5|\n",
      "+--------+---+-----------+----+---+--------+\n",
      "|weaksubj|  1|  abandoned| adj|  n|negative|\n",
      "|weaksubj|  1|abandonment|noun|  n|negative|\n",
      "|weaksubj|  1|    abandon|verb|  y|negative|\n",
      "+--------+---+-----------+----+---+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weaksubj</td>\n",
       "      <td>1</td>\n",
       "      <td>abandonment</td>\n",
       "      <td>noun</td>\n",
       "      <td>n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weaksubj</td>\n",
       "      <td>1</td>\n",
       "      <td>abandon</td>\n",
       "      <td>verb</td>\n",
       "      <td>y</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>abase</td>\n",
       "      <td>verb</td>\n",
       "      <td>y</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _c0 _c1          _c2   _c3 _c4       _c5\n",
       "1    weaksubj   1  abandonment  noun   n  negative\n",
       "2    weaksubj   1      abandon  verb   y  negative\n",
       "3  strongsubj   1        abase  verb   y  negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import sentiment dictionnary \n",
    "sentiment_with_schema = spark.read.load(\"dataset/dictionary.tsv\",\n",
    "                     format=\"csv\", sep=r'\\t', Schema=sentimentSchema, header=\"false\", mode = \"PERMISSIVE\")\n",
    " \n",
    "sentiment_with_schema.show(3)\n",
    "pdsentiment = sentiment_with_schema.toPandas()\n",
    "pdsentiment[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    intensity _c1         word word_type ny posititvity\n",
      "1    weaksubj   1  abandonment      noun  n    negative\n",
      "2    weaksubj   1      abandon      verb  y    negative\n",
      "3  strongsubj   1        abase      verb  y    negative\n",
      "\n",
      "         intensity   _c1  word word_type    ny posititvity\n",
      "count         8221  8221  8221      8221  8221        8221\n",
      "unique           2     1  6878        13     7           7\n",
      "top     strongsubj     1     1       adj     n    negative\n",
      "freq          5569  8221     8      3249  6595        4902\n"
     ]
    }
   ],
   "source": [
    "#panda summary\n",
    "pdsentiment = pdsentiment.rename(columns={\"_c0\":\"intensity\",\"_c2\": \"word\",\"_c3\":\"word_type\", \"_c4\":\"ny\", \"_c5\":\"posititvity\"})\n",
    "print(pdsentiment[1:4])\n",
    "print(\"\")\n",
    "print(pdsentiment.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id keyword location                                               text  \\\n",
      "0  1    None     None  Our Deeds are the Reason of this #earthquake M...   \n",
      "1  4    None     None             Forest fire near La Ronge Sask. Canada   \n",
      "2  5    None     None  All residents asked to 'shelter in place' are ...   \n",
      "3  6    None     None  13,000 people receive #wildfires evacuation or...   \n",
      "4  7    None     None  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "  target                                                new  \n",
      "0      1  [Our, Deeds, are, the, Reason, of, this, #eart...  \n",
      "1      1     [Forest, fire, near, La, Ronge, Sask., Canada]  \n",
      "2      1  [All, residents, asked, to, 'shelter, in, plac...  \n",
      "3      1  [13,000, people, receive, #wildfires, evacuati...  \n",
      "4      1  [Just, got, sent, this, photo, from, Ruby, #Al...  \n",
      "\n",
      "            id keyword location  \\\n",
      "count     8387    7987     5080   \n",
      "unique    8302     223     3340   \n",
      "top     #Truth       0      USA   \n",
      "freq         7     246      104   \n",
      "\n",
      "                                                     text target  \\\n",
      "count                                                7611   7176   \n",
      "unique                                               7486      2   \n",
      "top     11-Year-Old Boy Charged With Manslaughter of T...      0   \n",
      "freq                                                   10   4095   \n",
      "\n",
      "                                                      new  \n",
      "count                                                7611  \n",
      "unique                                               7486  \n",
      "top     [11-Year-Old, Boy, Charged, With, Manslaughter...  \n",
      "freq                                                   10  \n",
      "Class of new text:\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Splitting the text in panda /summary \n",
    "disaster_with_schemapd[\"new\"]= disaster_with_schemapd[\"text\"].str.split(\" \")\n",
    "print(disaster_with_schemapd.head(5))\n",
    "print(\"\")\n",
    "print(disaster_with_schemapd.describe())\n",
    "#print(disaster_with_schemapd['new'][3][1]) #query single element list of list \n",
    "print(\"Class of new text:\")\n",
    "print(type(disaster_with_schemapd['new']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+------------------+----------+------+---------+----------+\n",
      "|mainID|   id|keyword|          location|      word|target|  hashtag|     lword|\n",
      "+------+-----+-------+------------------+----------+------+---------+----------+\n",
      "|     1|   10|   null|              null|     flood|     1|   #flood|     flood|\n",
      "|     2|   10|   null|              null|  disaster|     1|#disaster|  disaster|\n",
      "|     3|   10|   null|              null|     Heavy|     1|         |     heavy|\n",
      "|     4|   10|   null|              null|      rain|     1|         |      rain|\n",
      "|     5|   10|   null|              null|    causes|     1|         |    causes|\n",
      "|     6|   10|   null|              null|     flash|     1|         |     flash|\n",
      "|     7|   10|   null|              null|  flooding|     1|         |  flooding|\n",
      "|     8|   10|   null|              null|        of|     1|         |        of|\n",
      "|     9|   10|   null|              null|   streets|     1|         |   streets|\n",
      "|    10|   10|   null|              null|        in|     1|         |        in|\n",
      "|    11|   10|   null|              null|  Manitou,|     1|         |  manitou,|\n",
      "|    12|   10|   null|              null|  Colorado|     1|         |  colorado|\n",
      "|    13|   10|   null|              null|   Springs|     1|         |   springs|\n",
      "|    14|   10|   null|              null|     areas|     1|         |     areas|\n",
      "|    15|10004|tsunami|in the Word of God|GreenLacey|     0|         |greenlacey|\n",
      "|    16|10004|tsunami|in the Word of God|  GodsLove|     0|         |  godslove|\n",
      "|    17|10004|tsunami|in the Word of God|      amp;|     0|         |      amp;|\n",
      "|    18|10004|tsunami|in the Word of God|    thankU|     0|  #thankU|    thanku|\n",
      "|    19|10004|tsunami|in the Word of God|        my|     0|         |        my|\n",
      "|    20|10004|tsunami|in the Word of God|    sister|     0|         |    sister|\n",
      "|    21|10004|tsunami|in the Word of God|       for|     0|         |       for|\n",
      "|    22|10004|tsunami|in the Word of God|        RT|     0|         |        rt|\n",
      "|    23|10004|tsunami|in the Word of God|        of|     0|         |        of|\n",
      "|    24|10004|tsunami|in the Word of God|       NEW|     0|         |       new|\n",
      "|    25|10004|tsunami|in the Word of God|     VIDEO|     0|         |     video|\n",
      "+------+-----+-------+------------------+----------+------+---------+----------+\n",
      "only showing top 25 rows\n",
      "\n",
      "+-----------+\n",
      "|Total_words|\n",
      "+-----------+\n",
      "|      66821|\n",
      "+-----------+\n",
      "\n",
      "+---------+\n",
      "|locations|\n",
      "+---------+\n",
      "|     2141|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In pyspark \n",
    "disaster_sample_expl = sample_disaster.select(\"id\",\"keyword\",\"location\", explode(split(col(\"text\"), \" \")).alias(\"word\"),\"target\")\n",
    "\n",
    "w = Window().orderBy(\"id\")\n",
    "#Add an ID for all word, set an hashtag column, get rid of the hashtag in the word column \n",
    "disaster_sample_expl = disaster_sample_expl.select(row_number().over(w).alias(\"mainID\"), col(\"*\"))\\\n",
    "                        .withColumn((\"hashtag\"),regexp_extract(col('word'), '#.*', 0))\\\n",
    "                        .withColumn((\"word\"),regexp_extract(col('word'), '[a-zA-Z].*', 0))\n",
    "\n",
    "#a lower column is created for optimizing merging capacities with other tables (as seen later)\n",
    "disaster_sample_expl = disaster_sample_expl.select(\"*\",lower(col('word')).alias(\"lword\"))\n",
    "disaster_sample_expl.show(25)\n",
    "disaster_sample_expl.select(count(\"id\").alias(\"Total_words\")).show() \n",
    "disaster_sample_expl.select(countDistinct(\"location\").alias(\"locations\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+\n",
      "|intensity|      lword|positivity|\n",
      "+---------+-----------+----------+\n",
      "| weaksubj|  abandoned|  negative|\n",
      "| weaksubj|abandonment|  negative|\n",
      "| weaksubj|    abandon|  negative|\n",
      "+---------+-----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sentiment columns\n",
    "#\"_c0\":\"intensity\",\"_c2\": \"word\",\"_c3\":\"word_type\", \"_c4\":\"ny\", \"_c5\":\"posititvity\"\n",
    "sentiment_renamed = sentiment_with_schema.withColumnRenamed(\"_c0\",\"intensity\") \\\n",
    "                        .withColumnRenamed(\"_c1\",\"numb\") \\\n",
    "                        .withColumnRenamed(\"_c2\",\"lword\") \\\n",
    "                        .withColumnRenamed(\"_c3\",\"word_type\") \\\n",
    "                        .withColumnRenamed(\"_c4\",\"ny\") \\\n",
    "                        .withColumnRenamed(\"_c5\",\"positivity\") \\\n",
    "                        .withColumn((\"lword\"),lower(\"lword\"))\n",
    "sentiment_renamed = sentiment_renamed.drop(*['numb', 'ny','word_type'])\n",
    "sentiment_renamed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my own disaster table with an associated categorisation \n",
    "row_in=[(\"flood\",\"natural\"),\n",
    "        (\"fire\",\"natural\"),\n",
    "        (\"wave\",\"natural\"),\n",
    "        (\"extreme weather\",\"natural\"),\n",
    "        (\"tsunami\",\"natural\"),\n",
    "        (\"lightning\",\"natural\"),\n",
    "        (\"Earthquake\",\"natural\"),\n",
    "        (\"Apocalyptic\",\"description\"),\n",
    "        (\"disaster\",\"description\"),\n",
    "        (\"catastrophe\",\"description\"),\n",
    "        (\"tragedy\",\"description\"),\n",
    "        (\"doom\",\"description\"),\n",
    "        (\"death\",\"description\"),\n",
    "        (\"hell\",\"description\"),\n",
    "        (\"riot\",\"human-related\"),\n",
    "        (\"terrorism\",\"human-related\"),\n",
    "        (\"war\",\"human-related\"),\n",
    "        (\"warfare\",\"human-related\"),\n",
    "        (\"terror\",\"description\"),\n",
    "        (\"cataclysm\",\"description\"),\n",
    "        (\"agression\",\"description\"),\n",
    "        (\"killing\",\"description\"),\n",
    "        (\"burn\",\"description\"),\n",
    "        (\"burning\",\"description\"),\n",
    "        (\"suicide\",\"description\"),\n",
    "        (\"drawn\",\"description\"),\n",
    "        (\"armageddon\",\"human-related\"),\n",
    "        (\"hurricanes\",\"natural\"),\n",
    "        (\"tornados\",\"natural\"),\n",
    "        (\"cyclones\",\"natural\"),\n",
    "        (\"Wildfires\",\"natural\"),\n",
    "        (\"famine\",\"natural\"),\n",
    "        (\"droughts\",\"natural\"),\n",
    "        (\"landslide\",\"natural\"),\n",
    "        (\"wildfires\",\"natural\"), \n",
    "        (\"ambulance\",\"services\"),\n",
    "        (\"emergency\",\"services\"),\n",
    "        (\"arrest\",\"services\"),\n",
    "        (\"police\",\"services\"),\n",
    "        (\"help\",\"services\"),\n",
    "        (\"bleeding\",\"description\"),\n",
    "        (\"slaughter\",\"description\"),\n",
    "        (\"dead\",\"description\"),\n",
    "        (\"fireman\",\"services\"),\n",
    "        (\"military\",\"services\"),\n",
    "        (\"assistance\",\"services\"),\n",
    "        (\"911\",\"services\")\n",
    "       ]\n",
    "schema = StructType([StructField('lword', StringType(),True),\n",
    "                     StructField('disaster_type', StringType(),True)])\n",
    "disaster_words = spark.createDataFrame(data = row_in,schema = schema).withColumn((\"lword\"),lower(\"lword\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+-------+------------------+----------+----------+---------+------+\n",
      "|               lword|mainID|   id|keyword|          location| intensity|positivity|  hashtag|target|\n",
      "+--------------------+------+-----+-------+------------------+----------+----------+---------+------+\n",
      "|               flood|     1|   10|   null|              null|      null|      null|   #flood|     1|\n",
      "|            disaster|     2|   10|   null|              null|strongsubj|  negative|#disaster|     1|\n",
      "|               heavy|     3|   10|   null|              null|      null|      null|         |     1|\n",
      "|                rain|     4|   10|   null|              null|      null|      null|         |     1|\n",
      "|              causes|     5|   10|   null|              null|      null|      null|         |     1|\n",
      "|               flash|     6|   10|   null|              null|  weaksubj|  negative|         |     1|\n",
      "|            flooding|     7|   10|   null|              null|      null|      null|         |     1|\n",
      "|                  of|     8|   10|   null|              null|      null|      null|         |     1|\n",
      "|             streets|     9|   10|   null|              null|      null|      null|         |     1|\n",
      "|                  in|    10|   10|   null|              null|      null|      null|         |     1|\n",
      "|            manitou,|    11|   10|   null|              null|      null|      null|         |     1|\n",
      "|            colorado|    12|   10|   null|              null|      null|      null|         |     1|\n",
      "|             springs|    13|   10|   null|              null|      null|      null|         |     1|\n",
      "|               areas|    14|   10|   null|              null|      null|      null|         |     1|\n",
      "|          greenlacey|    15|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|            godslove|    16|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                amp;|    17|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|              thanku|    18|10004|tsunami|in the Word of God|      null|      null|  #thankU|     0|\n",
      "|                  my|    19|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|              sister|    20|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                 for|    21|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                  rt|    22|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                  of|    23|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                 new|    24|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|               video|    25|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|http://t.co/cybks...|    26|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                 the|    27|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|              coming|    28|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|         apocalyptic|    29|10004|tsunami|in the Word of God|strongsubj|  negative|         |     0|\n",
      "|                  us|    30|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|          earthquake|    31|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                amp;|    32|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|             tsunami|    33|10004|tsunami|in the Word of God|      null|      null|         |     0|\n",
      "|                gail|    34|10009|twister|  Calgary, Alberta|      null|      null|         |     1|\n",
      "|                 and|    35|10009|twister|  Calgary, Alberta|      null|      null|         |     1|\n",
      "+--------------------+------+-----+-------+------------------+----------+----------+---------+------+\n",
      "only showing top 35 rows\n",
      "\n",
      "+-------------+\n",
      "|Total_hashtag|\n",
      "+-------------+\n",
      "|         1850|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#merging sentiment and disaster tables\n",
    "Combined = disaster_sample_expl.join(sentiment_renamed,\"lword\",how=\"left\")\n",
    "#removing duplicates\n",
    "Combined = Combined.select(\"lword\",\"mainID\",\"id\",\"keyword\",\"location\",\"intensity\", \"positivity\",\"hashtag\",\"target\").distinct()\n",
    "Combined.show(35)\n",
    "Combined.select(count(when(col(\"hashtag\") != \"\",True)).alias(\"Total_hashtag\")).show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+-------+----------------+----------+----------+---------+------+-------------+\n",
      "|               lword|mainID|   id|keyword|        location| intensity|positivity|  hashtag|target|disaster_type|\n",
      "+--------------------+------+-----+-------+----------------+----------+----------+---------+------+-------------+\n",
      "|               flood|     1|   10|   null|            null|      null|      null|   #flood|     1|      natural|\n",
      "|            disaster|     2|   10|   null|            null|strongsubj|  negative|#disaster|     1|  description|\n",
      "|               heavy|     3|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|                rain|     4|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|              causes|     5|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|               flash|     6|   10|   null|            null|  weaksubj|  negative|         |     1|         null|\n",
      "|            flooding|     7|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|                  of|     8|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|             streets|     9|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|                  in|    10|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|            manitou,|    11|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|            colorado|    12|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|             springs|    13|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|               areas|    14|   10|   null|            null|      null|      null|         |     1|         null|\n",
      "|          greenlacey|    15|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|            godslove|    16|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                amp;|    17|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|              thanku|    18|10004|tsunami|                |      null|      null|  #thankU|     0|         null|\n",
      "|                  my|    19|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|              sister|    20|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                 for|    21|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                  rt|    22|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                  of|    23|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                 new|    24|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|               video|    25|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|http://t.co/cybks...|    26|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|                 the|    27|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|              coming|    28|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|         apocalyptic|    29|10004|tsunami|                |strongsubj|  negative|         |     0|  description|\n",
      "|                  us|    30|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|          earthquake|    31|10004|tsunami|                |      null|      null|         |     0|      natural|\n",
      "|                amp;|    32|10004|tsunami|                |      null|      null|         |     0|         null|\n",
      "|             tsunami|    33|10004|tsunami|                |      null|      null|         |     0|      natural|\n",
      "|                gail|    34|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                 and|    35|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|             russell|    36|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                 saw|    37|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                lots|    38|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                  of|    39|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                hail|    40|10009|twister|Calgary, Alberta|strongsubj|  positive|         |     1|         null|\n",
      "|                  at|    41|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|               their|    42|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|              dalroy|    43|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                home|    44|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                    |    45|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                they|    46|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                have|    47|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|               video|    48|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                  of|    49|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|             twister|    50|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                    |    51|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                mile|    52|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                from|    53|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|               their|    54|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                home|    55|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                 yyc|    56|10009|twister|Calgary, Alberta|      null|      null|     #yyc|     1|         null|\n",
      "|http://t.co/3vfke...|    57|10009|twister|Calgary, Alberta|      null|      null|         |     1|         null|\n",
      "|                want|    58|10010|twister|            null|strongsubj|  positive|         |     0|         null|\n",
      "|             twister|    59|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|             tickets|    60|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 and|    61|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                   a|    62|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|              chance|    63|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                  at|    64|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                   a|    65|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 vip|    66|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|          experience|    67|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                  to|    68|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 see|    69|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|           shania!!!|    70|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|               click|    71|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|               here:|    72|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|http://t.co/964dk...|    73|10010|twister|            null|      null|      null|         |     0|         null|\n",
      "|                    |    74|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                  if|    75|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                   a|    76|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|           landslide|    77|10012|twister|  Las Vegas, NV |      null|      null|         |  null|      natural|\n",
      "|             tumbles|    78|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                down|    79|10012|twister|  Las Vegas, NV |  weaksubj|  negative|         |  null|         null|\n",
      "|            todayi'm|    80|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                  on|    81|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                your|    82|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|                side|    83|10012|twister|  Las Vegas, NV |      null|      null|         |  null|         null|\n",
      "|               brain|    84|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|             twister|    85|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|           homefolks|    86|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 are|    87|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|         opinionated|    88|10014|twister|            null|strongsubj|  negative|         |     0|         null|\n",
      "|                over|    89|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|             against|    90|10014|twister|            null|  weaksubj|  negative|         |     0|         null|\n",
      "|            proposal|    91|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|          modernized|    92|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|             canada:|    93|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 omw|    94|10014|twister|            null|      null|      null|         |     0|         null|\n",
      "|             twister|    95|10018|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 was|    96|10018|twister|            null|      null|      null|         |     0|         null|\n",
      "|                 fun|    97|10018|twister|            null|strongsubj|  positive|         |     0|         null|\n",
      "|                 fun|    97|10018|twister|            null|strongsubj|  negative|         |     0|         null|\n",
      "|https://t.co/qct6...|    98|10018|twister|            null|      null|      null|         |     0|         null|\n",
      "|               brain|    99|10020|twister|            null|      null|      null|         |     0|         null|\n",
      "+--------------------+------+-----+-------+----------------+----------+----------+---------+------+-------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join my disaster table - standardize the state of the tweets \n",
    "Combinedd = Combined.join(disaster_words,\"lword\", how='left')\\\n",
    "                    .withColumn((\"location\"),regexp_extract(col('location'), '.*,.*', 0))\\\n",
    "                    .orderBy(\"mainID\")\n",
    "Combinedd.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|Total_disaster_word|\n",
      "+-------------------+\n",
      "|                951|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#how many disaster words fit the dataset ?\n",
    "Combinedd.select(count(when(col(\"disaster_type\") != \"\",True)).alias(\"Total_disaster_word\")).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     lword|count|\n",
      "+----------+-----+\n",
      "|    people|  115|\n",
      "| emergency|   90|\n",
      "|  disaster|   71|\n",
      "|   burning|   70|\n",
      "|    police|   67|\n",
      "|   suicide|   65|\n",
      "|   content|   64|\n",
      "|california|   63|\n",
      "|   youtube|   58|\n",
      "|   nuclear|   56|\n",
      "|    severe|   56|\n",
      "| hiroshima|   53|\n",
      "|  families|   51|\n",
      "| buildings|   50|\n",
      "|    killed|   47|\n",
      "|   another|   46|\n",
      "|    attack|   45|\n",
      "|    should|   43|\n",
      "|    better|   42|\n",
      "|   bombing|   42|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing top words with at least 5 digits /avoiding operators/ and their respective sum\n",
    "Combinedd.filter(length(\"lword\") > 5) \\\n",
    "    .groupBy('lword') \\\n",
    "    .count().sort('count', ascending=False).show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|mainID|count|\n",
      "+------+-----+\n",
      "|  1829|    2|\n",
      "| 63087|    2|\n",
      "|  4935|    2|\n",
      "+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top sentence with disaster words\n",
    "Combinedd.filter(col(\"lword\") != \"\") \\\n",
    "    .groupBy('mainID') \\\n",
    "    .count().sort('count', ascending=False).show(3) \n",
    "\n",
    "#number of sentence with disaster word\n",
    "Combinedd.filter(col(\"disaster_type\") != \"\") \\\n",
    "    .select(col(\"id\")).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering business questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----+---------------+--------------------+---------+----------+-------+------+-------------+\n",
      "|     lword|mainID|   id|        keyword|            location|intensity|positivity|hashtag|target|disaster_type|\n",
      "+----------+------+-----+---------------+--------------------+---------+----------+-------+------+-------------+\n",
      "|      help|   747|10116|       upheaval|                    | weaksubj|  positive|       |     0|     services|\n",
      "|    police|  1321|10207|violent%20storm|                    |     null|      null|       |  null|     services|\n",
      "|    police|  2095|10331|         weapon|        New York, NY|     null|      null|       |     1|     services|\n",
      "|    police|  2326|10360|        weapons|                    |     null|      null|       |     0|     services|\n",
      "|      help|  2470|10378|        weapons|                    | weaksubj|  positive|       |  null|     services|\n",
      "|      help|  2494| 1038|       bleeding|     Vero Beach , FL| weaksubj|  positive|       |     0|     services|\n",
      "|      help|  2617|10392|      whirlwind|                    | weaksubj|  positive|       |     0|     services|\n",
      "|      help|  3586|10524|       wildfire|                null| weaksubj|  positive|       |     1|     services|\n",
      "| emergency|  3894|10568|      windstorm|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4057|10587|        wounded|Maracay y Nirgua,...|     null|      null|       |     1|     services|\n",
      "|assistance|  4082|10589|        wounded|      Scottsdale, AZ|     null|      null|       |     0|     services|\n",
      "|    police|  4144|10600|        wounded|                    |     null|      null|       |     1|     services|\n",
      "|    police|  4153|10600|        wounded|                    |     null|      null|       |     1|     services|\n",
      "|    police|  4213|10612|        wounded|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4224|10616|        wounded|    Washington, D.C.|     null|      null|       |     1|     services|\n",
      "|    police|  4238|10620|        wounded|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4247|10620|        wounded|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4270|10623|        wounded|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4287|10625|        wounded|                null|     null|      null|       |     1|     services|\n",
      "|    police|  4320|10628|        wounded|                    |     null|      null|       |     1|     services|\n",
      "|    police|  4369|10632|        wounded|Paterson, New Jer...|     null|      null|       |     1|     services|\n",
      "|    police|  4378|10632|        wounded|Paterson, New Jer...|     null|      null|       |     1|     services|\n",
      "|      help|  4449|10655|         wounds|   Rutherfordton, NC| weaksubj|  positive|       |     0|     services|\n",
      "|    police|  5868|10839|           null|                null|     null|      null|       |     1|     services|\n",
      "|      help|  6666| 1149|         blight|                    | weaksubj|  positive|       |     0|     services|\n",
      "|      help|  7408| 1275|          blood|                null| weaksubj|  positive|       |     0|     services|\n",
      "|      help|  7588| 1301|         bloody|Level 3 Garrison,...| weaksubj|  positive|       |     0|     services|\n",
      "|      help|  8081|  138|       accident|     Baton Rouge, LA| weaksubj|  positive|       |     0|     services|\n",
      "| emergency|  8223|   14|           null|                null|     null|      null|       |     1|     services|\n",
      "|    police|  8896| 1494|    body%20bags|    washington, d.c.|     null|      null|       |     0|     services|\n",
      "+----------+------+-----+---------------+--------------------+---------+----------+-------+------+-------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#who needs assisance\n",
    "Combinedd.filter(col(\"disaster_type\") == \"services\") \\\n",
    "    .select('*') \\\n",
    "    .show(30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----+-----------------+--------------------+----------+----------+------------+------+-------------+\n",
      "|      lword|mainID|   id|          keyword|            location| intensity|positivity|     hashtag|target|disaster_type|\n",
      "+-----------+------+-----+-----------------+--------------------+----------+----------+------------+------+-------------+\n",
      "|   disaster|     2|   10|             null|                null|strongsubj|  negative|   #disaster|     1|  description|\n",
      "|apocalyptic|    29|10004|          tsunami|                    |strongsubj|  negative|            |     0|  description|\n",
      "|   disaster|   397|10058|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   403|10058|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   446|10067|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   452|10067|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   461|10069|          typhoon|          Tema,Accra|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   467|10069|          typhoon|          Tema,Accra|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   478|10071|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   484|10071|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   545|10080|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   551|10080|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   560|10081|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   566|10081|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   575|10083|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   581|10084|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   587|10084|          typhoon|                null|strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   663|10105|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   669|10105|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   677|10106|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|   disaster|   683|10106|          typhoon|                    |strongsubj|  negative|            |     1|  description|\n",
      "|     terror|  2013|10310|           weapon|                    |strongsubj|  negative|     #terror|     1|  description|\n",
      "|       hell|  7444| 1279|           bloody| Walthamstow, London|strongsubj|  negative|            |     0|  description|\n",
      "|       hell|  7571| 1301|           bloody|Level 3 Garrison,...|strongsubj|  negative|            |     0|  description|\n",
      "|   disaster| 10114| 1673|bridge%20collapse|                null|strongsubj|  negative|            |  null|  description|\n",
      "|       burn| 12410| 1976|     bush%20fires|                null|strongsubj|  negative|            |     1|  description|\n",
      "|catastrophe| 13329| 2109|      catastrophe|                null|strongsubj|  negative|            |     1|  description|\n",
      "|catastrophe| 13367| 2111|      catastrophe|  West Virginia, USA|strongsubj|  negative|            |     0|  description|\n",
      "|catastrophe| 13385| 2112|      catastrophe|                null|strongsubj|  negative|#catastrophe|     0|  description|\n",
      "|catastrophe| 13390| 2113|      catastrophe|                    |strongsubj|  negative|            |     0|  description|\n",
      "+-----------+------+-----+-----------------+--------------------+----------+----------+------------+------+-------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gravity of the situation \n",
    "Combinedd.filter((col(\"intensity\") == \"strongsubj\") & (col(\"disaster_type\") != \"\")) \\\n",
    "    .select('*') \\\n",
    "    .show(30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       location|count|\n",
      "+---------------+-----+\n",
      "|Los Angeles, CA|  264|\n",
      "|    Chicago, IL|  182|\n",
      "|California, USA|  159|\n",
      "+---------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#states higher incident \n",
    "Combinedd.filter((col(\"lword\") != \"\")  & (col(\"location\") != \"\")) \\\n",
    "    .groupBy('location') \\\n",
    "    .count().sort('count', ascending=False).show(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
